{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üöó Parking Slot Detection - YOLOv8 Training\n",
                "\n",
                "This notebook trains a YOLOv8 Nano model to detect:\n",
                "- **Cars** (occupied parking slots)\n",
                "- **Empty slots** (available parking spaces)\n",
                "\n",
                "## Instructions\n",
                "1. **Runtime > Change runtime type > GPU (T4)**\n",
                "2. Upload your `formatted_dataset.zip` when prompted\n",
                "3. Run all cells sequentially\n",
                "4. Download the trained model at the end"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install required packages\n",
                "!pip install ultralytics -q\n",
                "\n",
                "# Verify GPU is available\n",
                "import torch\n",
                "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Upload Your Dataset\n",
                "\n",
                "**Before running this cell:**\n",
                "1. On your local machine, zip the `formatted_dataset` folder:\n",
                "   - Navigate to `C:\\Users\\akshaya\\Desktop\\mini`\n",
                "   - Right-click `formatted_dataset` ‚Üí Send to ‚Üí Compressed (zipped) folder\n",
                "   - This creates `formatted_dataset.zip`\n",
                "2. Run the cell below and upload the zip file when prompted"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "import zipfile\n",
                "import os\n",
                "\n",
                "# Upload the dataset zip file\n",
                "print(\"üìÅ Please upload 'formatted_dataset.zip'...\")\n",
                "uploaded = files.upload()\n",
                "\n",
                "# Extract the dataset\n",
                "zip_filename = list(uploaded.keys())[0]\n",
                "print(f\"\\nüì¶ Extracting {zip_filename}...\")\n",
                "\n",
                "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
                "    zip_ref.extractall('/content/')\n",
                "\n",
                "print(\"‚úÖ Dataset extracted successfully!\")\n",
                "\n",
                "# List contents\n",
                "!ls -la /content/formatted_dataset/"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Create Dataset Configuration (data.yaml)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create data.yaml configuration file\n",
                "data_yaml_content = \"\"\"path: /content/formatted_dataset\n",
                "train: images/train\n",
                "val: images/val\n",
                "\n",
                "names:\n",
                "  0: car\n",
                "  1: empty\n",
                "\"\"\"\n",
                "\n",
                "with open('/content/data.yaml', 'w') as f:\n",
                "    f.write(data_yaml_content)\n",
                "\n",
                "print(\"‚úÖ data.yaml created!\")\n",
                "print(\"\\nüìÑ Contents:\")\n",
                "!cat /content/data.yaml"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Verify Dataset Structure"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "# Check dataset structure\n",
                "base_path = '/content/formatted_dataset'\n",
                "\n",
                "train_images = os.path.join(base_path, 'images', 'train')\n",
                "train_labels = os.path.join(base_path, 'labels', 'train')\n",
                "val_images = os.path.join(base_path, 'images', 'val')\n",
                "val_labels = os.path.join(base_path, 'labels', 'val')\n",
                "\n",
                "print(\"üìä Dataset Statistics:\")\n",
                "print(f\"  Train Images: {len(os.listdir(train_images)) if os.path.exists(train_images) else 'NOT FOUND'}\")\n",
                "print(f\"  Train Labels: {len(os.listdir(train_labels)) if os.path.exists(train_labels) else 'NOT FOUND'}\")\n",
                "print(f\"  Val Images:   {len(os.listdir(val_images)) if os.path.exists(val_images) else 'NOT FOUND'}\")\n",
                "print(f\"  Val Labels:   {len(os.listdir(val_labels)) if os.path.exists(val_labels) else 'NOT FOUND'}\")\n",
                "\n",
                "# Preview a few labels\n",
                "print(\"\\nüîç Sample Labels (first 3):\")\n",
                "label_files = os.listdir(train_labels)[:3]\n",
                "for lf in label_files:\n",
                "    print(f\"\\n--- {lf} ---\")\n",
                "    with open(os.path.join(train_labels, lf), 'r') as f:\n",
                "        content = f.read()\n",
                "        print(content if content else \"(empty file)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Train YOLOv8 Model üöÄ\n",
                "\n",
                "This cell trains the model. Training time depends on:\n",
                "- Dataset size\n",
                "- Number of epochs\n",
                "- GPU type\n",
                "\n",
                "**Estimated time: 10-30 minutes** for 50 epochs with ~2000 images on T4 GPU."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from ultralytics import YOLO\n",
                "\n",
                "# Load a pretrained YOLOv8 Nano model\n",
                "model = YOLO('yolov8n.pt')\n",
                "\n",
                "# Train the model\n",
                "results = model.train(\n",
                "    data='/content/data.yaml',\n",
                "    epochs=50,           # Adjust as needed (more epochs = better accuracy but longer time)\n",
                "    imgsz=640,           # Image size\n",
                "    batch=16,            # Batch size (reduce if you get OOM errors)\n",
                "    device=0,            # Use GPU\n",
                "    workers=2,           # Number of data loading workers\n",
                "    patience=10,         # Early stopping patience\n",
                "    plots=True,          # Generate training plots\n",
                "    save=True,           # Save checkpoints\n",
                "    project='/content/runs/detect',\n",
                "    name='parking_detector'\n",
                ")\n",
                "\n",
                "print(\"\\n‚úÖ Training Complete!\")\n",
                "print(f\"üìÅ Model saved at: {results.save_dir}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Validate the Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the best trained model\n",
                "best_model = YOLO('/content/runs/detect/parking_detector/weights/best.pt')\n",
                "\n",
                "# Run validation\n",
                "metrics = best_model.val()\n",
                "\n",
                "print(\"\\nüìà Validation Metrics:\")\n",
                "print(f\"  mAP50: {metrics.box.map50:.4f}\")\n",
                "print(f\"  mAP50-95: {metrics.box.map:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Visualize Training Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from IPython.display import Image, display\n",
                "import os\n",
                "\n",
                "results_dir = '/content/runs/detect/parking_detector/'\n",
                "\n",
                "# Display training plots\n",
                "plots = ['results.png', 'confusion_matrix.png', 'F1_curve.png', 'P_curve.png', 'R_curve.png']\n",
                "\n",
                "for plot in plots:\n",
                "    plot_path = os.path.join(results_dir, plot)\n",
                "    if os.path.exists(plot_path):\n",
                "        print(f\"\\nüìä {plot}:\")\n",
                "        display(Image(filename=plot_path, width=800))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Test on Sample Images"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from IPython.display import Image, display\n",
                "import os\n",
                "\n",
                "# Run inference on validation images\n",
                "val_images_dir = '/content/formatted_dataset/images/val'\n",
                "sample_images = os.listdir(val_images_dir)[:5]  # First 5 images\n",
                "\n",
                "print(\"üîç Running inference on sample images...\\n\")\n",
                "\n",
                "for img_name in sample_images:\n",
                "    img_path = os.path.join(val_images_dir, img_name)\n",
                "    results = best_model(img_path)\n",
                "    \n",
                "    # Save result\n",
                "    result_path = f'/content/result_{img_name}'\n",
                "    results[0].save(result_path)\n",
                "    \n",
                "    print(f\"üì∏ {img_name}:\")\n",
                "    display(Image(filename=result_path, width=600))\n",
                "    print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Download Trained Model üì•\n",
                "\n",
                "Download the trained model to use in your local Streamlit app.\n",
                "\n",
                "**After downloading:**\n",
                "1. Place `best.pt` in `C:\\Users\\akshaya\\Desktop\\mini\\`\n",
                "2. Run `streamlit run app.py`\n",
                "3. Select `best.pt` from the model dropdown in the sidebar"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "import shutil\n",
                "\n",
                "# Path to the best model\n",
                "best_model_path = '/content/runs/detect/parking_detector/weights/best.pt'\n",
                "last_model_path = '/content/runs/detect/parking_detector/weights/last.pt'\n",
                "\n",
                "# Copy to a simpler name\n",
                "shutil.copy(best_model_path, '/content/best.pt')\n",
                "\n",
                "print(\"üì¶ Downloading best.pt...\")\n",
                "print(\"\\nüí° After download, place this file in your 'mini' project folder!\")\n",
                "\n",
                "# Download the model\n",
                "files.download('/content/best.pt')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. (Optional) Download All Training Artifacts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "import shutil\n",
                "\n",
                "# Zip all training results\n",
                "shutil.make_archive('/content/training_results', 'zip', '/content/runs/detect/parking_detector')\n",
                "\n",
                "print(\"üì¶ Downloading all training artifacts...\")\n",
                "files.download('/content/training_results.zip')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üéâ Done!\n",
                "\n",
                "You have successfully trained a parking slot detection model!\n",
                "\n",
                "### Next Steps:\n",
                "1. Download `best.pt` to your local machine\n",
                "2. Place it in `C:\\Users\\akshaya\\Desktop\\mini\\`\n",
                "3. Run `streamlit run app.py`\n",
                "4. Select `best.pt` from the model dropdown\n",
                "5. Upload an image or video to test!\n",
                "\n",
                "### Model Classes:\n",
                "- **Class 0: car** - Detected vehicles (occupied slots)\n",
                "- **Class 1: empty** - Empty parking slots (available)"
            ]
        }
    ]
}